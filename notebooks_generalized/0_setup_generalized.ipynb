{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d1729b",
   "metadata": {},
   "source": [
    "# 🚀 Environment Setup & Validation - Generalized Pipeline\n",
    "\n",
    "This notebook sets up the environment and validates the configuration for the generalized financial sentiment analysis pipeline.\n",
    "\n",
    "**Key Features:**\n",
    "- Centralized configuration management\n",
    "- Environment validation and dependency checking\n",
    "- GPU/device detection and optimization\n",
    "- Pipeline state initialization\n",
    "- Model availability verification\n",
    "\n",
    "**Configuration-driven approach:** All settings loaded from `../config/pipeline_config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152fa192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:28:04,656 - pipeline.setup - INFO - 🚀 Starting Environment Setup - Generalized Pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration loaded from ../config/pipeline_config.json\n"
     ]
    }
   ],
   "source": [
    "# Import configuration system and utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.pipeline_utils import ConfigManager, StateManager, LoggingManager\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize configuration system\n",
    "config = ConfigManager('../config/pipeline_config.json')\n",
    "state = StateManager('../config/pipeline_state.json')\n",
    "logger_manager = LoggingManager(config, 'setup')\n",
    "logger = logger_manager.get_logger()\n",
    "\n",
    "logger.info(\"🚀 Starting Environment Setup - Generalized Pipeline\")\n",
    "print(\"📋 Configuration loaded from ../config/pipeline_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72fa1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:28:04,693 - pipeline.setup - INFO - 🔍 Validating environment and dependencies...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Environment Validation:\n",
      "   📍 Current working directory: /Users/matthew/Documents/deepmind_internship/notebooks_generalized\n",
      "   🐍 Python version: 3.11.13 (main, Jun  3 2025, 18:38:25) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "   🤗 Transformers version: 4.52.4\n",
      "   📊 Pandas version: 2.3.1\n",
      "   🔢 NumPy version: 1.26.4\n",
      "   🔧 Primary device: cpu\n",
      "   🍎 Apple Metal Performance Shaders (MPS) available\n",
      "✅ Environment validation completed\n"
     ]
    }
   ],
   "source": [
    "# Validate prerequisites and environment\n",
    "logger.info(\"🔍 Validating environment and dependencies...\")\n",
    "\n",
    "print(\"🔍 Environment Validation:\")\n",
    "print(f\"   📍 Current working directory: {os.getcwd()}\")\n",
    "print(f\"   🐍 Python version: {sys.version}\")\n",
    "print(f\"   🤗 Transformers version: {transformers.__version__}\")\n",
    "print(f\"   📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"   🔢 NumPy version: {np.__version__}\")\n",
    "\n",
    "# Device detection and configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"   🔧 Primary device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   🚀 CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   💾 CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"   🍎 Apple Metal Performance Shaders (MPS) available\")\n",
    "else:\n",
    "    print(\"   💻 Using CPU\")\n",
    "\n",
    "print(\"✅ Environment validation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a39852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:28:04,731 - pipeline.setup - INFO - 📋 Validating pipeline configuration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration Validation:\n",
      "   ✅ Configuration file found: ../config/pipeline_config.json\n",
      "   ✅ Utilities module found: ../src/pipeline_utils.py\n",
      "   📊 Data sources configured: 0\n",
      "   🤖 Models configured: 3\n",
      "   🏋️ Training epochs: 3\n",
      "   ✅ Configuration structure validated\n",
      "\n",
      "📁 Directory Structure:\n",
      "   ✅ ../data\n",
      "   ✅ ../models\n",
      "   ✅ ../results\n",
      "   ✅ ../config\n",
      "   ✅ ../src\n",
      "✅ Configuration validation completed\n"
     ]
    }
   ],
   "source": [
    "# Validate configuration and directory structure\n",
    "logger.info(\"📋 Validating pipeline configuration...\")\n",
    "\n",
    "print(\"📋 Configuration Validation:\")\n",
    "\n",
    "# Check if configuration files exist\n",
    "config_file = Path(\"../config/pipeline_config.json\")\n",
    "utils_file = Path(\"../src/pipeline_utils.py\")\n",
    "\n",
    "if config_file.exists():\n",
    "    print(f\"   ✅ Configuration file found: {config_file}\")\n",
    "else:\n",
    "    print(f\"   ❌ Configuration file missing: {config_file}\")\n",
    "\n",
    "if utils_file.exists():\n",
    "    print(f\"   ✅ Utilities module found: {utils_file}\")\n",
    "else:\n",
    "    print(f\"   ❌ Utilities module missing: {utils_file}\")\n",
    "\n",
    "# Validate configuration structure\n",
    "try:\n",
    "    data_config = config.get('data', {})\n",
    "    models_config = config.get('models', {})\n",
    "    training_config = config.get('training', {})\n",
    "    \n",
    "    print(f\"   📊 Data sources configured: {len(data_config.get('datasets', {}))}\")\n",
    "    print(f\"   🤖 Models configured: {len(models_config.get('base_models', []))}\")\n",
    "    print(f\"   🏋️ Training epochs: {training_config.get('num_epochs', 'Not set')}\")\n",
    "    print(\"   ✅ Configuration structure validated\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Configuration validation failed: {str(e)}\")\n",
    "    print(f\"   ❌ Configuration validation failed: {str(e)}\")\n",
    "\n",
    "# Check required directories\n",
    "required_dirs = [\"../data\", \"../models\", \"../results\", \"../config\", \"../src\"]\n",
    "print(\"\\n📁 Directory Structure:\")\n",
    "\n",
    "for dir_path in required_dirs:\n",
    "    path = Path(dir_path)\n",
    "    if path.exists():\n",
    "        print(f\"   ✅ {dir_path}\")\n",
    "    else:\n",
    "        print(f\"   ❌ {dir_path} (will be created as needed)\")\n",
    "        \n",
    "print(\"✅ Configuration validation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7c9ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:28:04,744 - pipeline.setup - INFO - 🤖 Checking model availability...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Model Availability Check:\n",
      "   ✅ tinybert-financial-classifier (huawei-noah/TinyBERT_General_4L_312D)\n",
      "   ✅ tinybert-financial-classifier (huawei-noah/TinyBERT_General_4L_312D)\n",
      "   ✅ finbert-tone (ProsusAI/finbert)\n",
      "\n",
      "📊 Model Summary:\n",
      "   ✅ Available: 2 models\n",
      "   ❌ Missing: 0 models\n",
      "\n",
      "📂 Data Availability:\n",
      "   ✅ Main dataset: ../data/FinancialPhraseBank/all-data.csv\n",
      "   ❌ Processed data dir: ../data/processed (will be created)\n",
      "✅ Model availability check completed\n",
      "   ✅ finbert-tone (ProsusAI/finbert)\n",
      "\n",
      "📊 Model Summary:\n",
      "   ✅ Available: 2 models\n",
      "   ❌ Missing: 0 models\n",
      "\n",
      "📂 Data Availability:\n",
      "   ✅ Main dataset: ../data/FinancialPhraseBank/all-data.csv\n",
      "   ❌ Processed data dir: ../data/processed (will be created)\n",
      "✅ Model availability check completed\n"
     ]
    }
   ],
   "source": [
    "# Model availability and base model verification\n",
    "logger.info(\"🤖 Checking model availability...\")\n",
    "\n",
    "print(\"🤖 Model Availability Check:\")\n",
    "\n",
    "# Check configured models\n",
    "models_config = config.get('models', {})\n",
    "base_models = models_config.get('base_models', [])\n",
    "available_models = []\n",
    "missing_models = []\n",
    "\n",
    "for model_config in base_models:\n",
    "    if model_config.get('enabled', True):\n",
    "        model_name = model_config['name']\n",
    "        model_id = model_config['model_id']\n",
    "        \n",
    "        try:\n",
    "            # Try to load tokenizer to verify model accessibility\n",
    "            from transformers import AutoTokenizer\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "            available_models.append(model_name)\n",
    "            print(f\"   ✅ {model_name} ({model_id})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            missing_models.append(model_name)\n",
    "            print(f\"   ❌ {model_name} ({model_id}) - {str(e)[:100]}...\")\n",
    "\n",
    "print(f\"\\n📊 Model Summary:\")\n",
    "print(f\"   ✅ Available: {len(available_models)} models\")\n",
    "print(f\"   ❌ Missing: {len(missing_models)} models\")\n",
    "\n",
    "if missing_models:\n",
    "    print(f\"\\n⚠️ Missing models will be downloaded during training.\")\n",
    "\n",
    "# Check data availability\n",
    "print(f\"\\n📂 Data Availability:\")\n",
    "data_config = config.get('data', {})\n",
    "\n",
    "# Check main raw data path\n",
    "raw_data_path = Path(f\"../{data_config.get('raw_data_path', '')}\")\n",
    "if raw_data_path.exists():\n",
    "    print(f\"   ✅ Main dataset: {raw_data_path}\")\n",
    "else:\n",
    "    print(f\"   ❌ Main dataset: {raw_data_path}\")\n",
    "\n",
    "# Check processed data directory\n",
    "processed_dir = Path(f\"../{data_config.get('processed_data_dir', '')}\")\n",
    "if processed_dir.exists():\n",
    "    print(f\"   ✅ Processed data dir: {processed_dir}\")\n",
    "else:\n",
    "    print(f\"   ❌ Processed data dir: {processed_dir} (will be created)\")\n",
    "\n",
    "print(\"✅ Model availability check completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e46667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:28:07,129 - pipeline.setup - INFO - 🔄 Initializing pipeline state...\n",
      "2025-08-08 16:28:07,132 - pipeline.setup - INFO - ✅ Environment setup completed successfully\n",
      "2025-08-08 16:28:07,132 - pipeline.setup - INFO - ✅ Environment setup completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Pipeline State Initialization:\n",
      "   ✅ Pipeline state initialized\n",
      "   📅 Setup timestamp: 2025-08-08T16:28:07.131245\n",
      "   🔧 Device configured: cpu\n",
      "   🤖 Models available: 2\n",
      "\n",
      "============================================================\n",
      "🎉 SETUP COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "📝 Next Steps:\n",
      "1. Run 1_data_processing_generalized.ipynb to process and prepare data\n",
      "2. Run 2_train_models_generalized.ipynb to train the models\n",
      "3. Continue with the sequential pipeline: 3 → 4 → 5 → 6\n",
      "\n",
      "🔧 Configuration Summary:\n",
      "   📊 Data source: data/FinancialPhraseBank/all-data.csv\n",
      "   🤖 Models configured: 3\n",
      "   🏋️ Training epochs: 3\n",
      "   📈 Batch size: 16\n",
      "\n",
      "📄 Setup report saved to: ../results/setup_report.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline state and complete setup\n",
    "logger.info(\"🔄 Initializing pipeline state...\")\n",
    "\n",
    "print(\"🔄 Pipeline State Initialization:\")\n",
    "\n",
    "# Initialize or update pipeline state\n",
    "setup_info = {\n",
    "    'setup_timestamp': datetime.now().isoformat(),\n",
    "    'python_version': sys.version,\n",
    "    'device': str(device),\n",
    "    'available_models': available_models if 'available_models' in locals() else [],\n",
    "    'missing_models': missing_models if 'missing_models' in locals() else [],\n",
    "    'configuration_valid': True,\n",
    "    'environment_ready': True\n",
    "}\n",
    "\n",
    "# Mark setup as completed\n",
    "state.mark_step_complete('setup_completed', **setup_info)\n",
    "\n",
    "print(\"   ✅ Pipeline state initialized\")\n",
    "print(f\"   📅 Setup timestamp: {setup_info['setup_timestamp']}\")\n",
    "print(f\"   🔧 Device configured: {setup_info['device']}\")\n",
    "print(f\"   🤖 Models available: {len(setup_info['available_models'])}\")\n",
    "\n",
    "# Display next steps\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎉 SETUP COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"📝 Next Steps:\")\n",
    "print(\"1. Run 1_data_processing_generalized.ipynb to process and prepare data\")\n",
    "print(\"2. Run 2_train_models_generalized.ipynb to train the models\")\n",
    "print(\"3. Continue with the sequential pipeline: 3 → 4 → 5 → 6\")\n",
    "\n",
    "print(f\"\\n🔧 Configuration Summary:\")\n",
    "print(f\"   📊 Data source: {data_config.get('raw_data_path', 'Not configured')}\")\n",
    "print(f\"   🤖 Models configured: {len(base_models)}\")\n",
    "print(f\"   🏋️ Training epochs: {training_config.get('num_epochs', 'Not configured')}\")\n",
    "print(f\"   📈 Batch size: {training_config.get('batch_size', 'Not configured')}\")\n",
    "\n",
    "logger.info(\"✅ Environment setup completed successfully\")\n",
    "\n",
    "# Save setup report\n",
    "setup_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'status': 'completed',\n",
    "    'environment': {\n",
    "        'python_version': sys.version,\n",
    "        'device': str(device),\n",
    "        'torch_version': torch.__version__,\n",
    "        'transformers_version': transformers.__version__\n",
    "    },\n",
    "    'configuration': {\n",
    "        'config_file_exists': config_file.exists() if 'config_file' in locals() else False,\n",
    "        'utils_file_exists': utils_file.exists() if 'utils_file' in locals() else False,\n",
    "        'models_configured': len(base_models),\n",
    "        'data_source_configured': bool(data_config.get('raw_data_path'))\n",
    "    },\n",
    "    'models': {\n",
    "        'available': available_models if 'available_models' in locals() else [],\n",
    "        'missing': missing_models if 'missing_models' in locals() else []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ensure results directory exists\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save setup report\n",
    "with open(results_dir / 'setup_report.json', 'w') as f:\n",
    "    json.dump(setup_report, f, indent=2)\n",
    "\n",
    "print(f\"\\n📄 Setup report saved to: {results_dir / 'setup_report.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
