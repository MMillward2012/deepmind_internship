
UNIVERSAL FINE-TUNING & PRUNING ANALYSIS SUMMARY
===============================================

üéØ PERFORMANCE OVERVIEW (ONNX):
‚Ä¢ Overall Accuracy: 79.1%
‚Ä¢ Error Rate: 20.9%
‚Ä¢ Average Confidence: 0.731
‚Ä¢ Model: tinybert-financial-classifier

üìä KEY METRICS FOR FINE-TUNING:
‚Ä¢ Most Problematic Classes: ['positive', 'negative']
‚Ä¢ Low Confidence Samples: 195 (16.1%)
‚Ä¢ High-Priority Samples: 253 errors + 195 low-conf

üîß RECOMMENDED FINE-TUNING STRATEGY:
‚Ä¢ Learning Rate: 5e-5 to 1e-4 (moderate fine-tuning)
‚Ä¢ Focus Areas: positive, negative
‚Ä¢ Target Keywords: pct, solutions, compared, new, increase

‚úÇÔ∏è RECOMMENDED PRUNING STRATEGY:
‚Ä¢ Conservative pruning (10-20%) - low confidence samples
‚Ä¢ Confidence Threshold: 0.9
‚Ä¢ Expected Coverage: 0.0%

üìã NEXT STEPS:
1. Use misclassified samples for hard negative mining
2. Focus fine-tuning on positive, negative classes
3. Apply confidence-based pruning with 0.9 threshold
4. Monitor performance on high-entropy samples
